{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "536e4ef2-b431-4600-9ceb-428b076cc7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Enrichment and Business Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55b8bb52-db57-4a96-b6b2-642c4b3a7ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**This notenook enriches the validated data with additional business metries and prepares it for analytic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54bb3af4-6ebd-4c21-9585-25cc5e31c708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data enrichment process...\n"
     ]
    }
   ],
   "source": [
    "# Configuration \n",
    "orders_stage = \"`event-driven-catalog`.default.order_stage\"\n",
    "customers_stage = \"`event-driven-catalog`.default.customers_stage\"\n",
    "products_stage = \"`event-driven-catalog`.default.products_stage\"\n",
    "inventory_stage = \"`event-driven-catalog`.default.inventory_stage\"\n",
    "shipping_stage = \"`event-driven-catalog`.default.shipping_stage\"\n",
    "enriched_orders_table = \"`event-driven-catalog`.default.enriched_orders\"\n",
    "customer_analytics_table = \"`event-driven-catalog`.default.customer_analytics\"\n",
    "products_analytics_table = \"`event-driven-catalog`.default.products_analytics\"\n",
    "\n",
    "print(\"Starting data enrichment process...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "073a238b-0ce5-4771-ac1f-33532731e09e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded all staging tables for enrichment\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Read all staging tables\n",
    "try:\n",
    "    df_orders = spark.read.table(orders_stage)\n",
    "    df_customers = spark.read.table(customers_stage)\n",
    "    df_products = spark.read.table(products_stage)\n",
    "    df_inventory = spark.read.table(inventory_stage)\n",
    "    df_shipping = spark.read.table(shipping_stage)\n",
    "    \n",
    "    print(\"Successfully loaded all staging tables for enrichment\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading staging tables: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37b92c05-3719-45e3-a08b-2c6de173f6a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched orders dataset created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create enriched orders dataset with all related information\n",
    "try:\n",
    "    # Rename ALL conflicting columns to avoid ambiguity\n",
    "    df_customers_renamed = df_customers.withColumnRenamed(\"created_timestamp\", \"customer_created_timestamp\") \\\n",
    "                                      .withColumnRenamed(\"batch_id\", \"customer_batch_id\") \\\n",
    "                                      .withColumnRenamed(\"processed_timestamp\", \"customer_processed_timestamp\") \\\n",
    "                                      .withColumnRenamed(\"source_system\", \"customer_source_system\") \\\n",
    "                                      .withColumnRenamed(\"lifecycle_stage\", \"customer_lifecycle_stage\")\n",
    "    \n",
    "    df_products_renamed = df_products.withColumnRenamed(\"created_timestamp\", \"product_created_timestamp\") \\\n",
    "                                    .withColumnRenamed(\"batch_id\", \"product_batch_id\") \\\n",
    "                                    .withColumnRenamed(\"processed_timestamp\", \"product_processed_timestamp\") \\\n",
    "                                    .withColumnRenamed(\"source_system\", \"product_source_system\") \\\n",
    "                                    .withColumnRenamed(\"currency\", \"product_currency\") \\\n",
    "                                    .withColumnRenamed(\"weight_kg\", \"product_weight_kg\") \\\n",
    "                                    .withColumnRenamed(\"stock_quantity\", \"product_stock_quantity\") \\\n",
    "                                    .withColumnRenamed(\"stock_status\", \"product_stock_status\") \\\n",
    "                                    .withColumnRenamed(\"price_segment\", \"product_price_segment\")\n",
    "    \n",
    "    df_inventory_renamed = df_inventory.withColumnRenamed(\"created_timestamp\", \"inventory_created_timestamp\") \\\n",
    "                                      .withColumnRenamed(\"batch_id\", \"inventory_batch_id\") \\\n",
    "                                      .withColumnRenamed(\"processed_timestamp\", \"inventory_processed_timestamp\") \\\n",
    "                                      .withColumnRenamed(\"source_system\", \"inventory_source_system\") \\\n",
    "                                      .withColumnRenamed(\"stock_status\", \"inventory_stock_status\")\n",
    "    \n",
    "    df_shipping_renamed = df_shipping.withColumnRenamed(\"created_timestamp\", \"shipping_created_timestamp\") \\\n",
    "                                    .withColumnRenamed(\"batch_id\", \"shipping_batch_id\") \\\n",
    "                                    .withColumnRenamed(\"processed_timestamp\", \"shipping_processed_timestamp\") \\\n",
    "                                    .withColumnRenamed(\"source_system\", \"shipping_source_system\") \\\n",
    "                                    .withColumnRenamed(\"currency\", \"shipping_currency\")\n",
    "                                    \n",
    "    \n",
    "    # Join orders with customers, products, inventory, and shipping\n",
    "    df_enriched_orders = df_orders \\\n",
    "        .join(df_customers_renamed, \"customer_id\", \"left\") \\\n",
    "        .join(df_products_renamed, \"product_id\", \"left\") \\\n",
    "        .join(df_inventory_renamed, \"product_id\", \"left\") \\\n",
    "        .join(df_shipping_renamed, \"order_id\", \"left\")\n",
    "    \n",
    "    # Add business metrics\n",
    "    df_enriched_orders = df_enriched_orders.withColumn(\n",
    "        \"order_profit_margin\",\n",
    "        F.col(\"order_amount\") * 0.3  # Assuming 30% profit margin\n",
    "    )\n",
    "    \n",
    "    # Add customer lifetime value estimation\n",
    "    df_enriched_orders = df_enriched_orders.withColumn(\n",
    "        \"estimated_clv\",\n",
    "        F.col(\"order_amount\") * F.when(F.col(\"customer_tier\") == \"premium\", 10)\n",
    "                                 .when(F.col(\"customer_tier\") == \"gold\", 7)\n",
    "                                 .when(F.col(\"customer_tier\") == \"silver\", 5)\n",
    "                                 .otherwise(3)\n",
    "    )\n",
    "    \n",
    "    # Add seasonal indicators\n",
    "    df_enriched_orders = df_enriched_orders.withColumn(\n",
    "        \"season\",\n",
    "        F.when(F.month(F.col(\"order_date\")).isin([12, 1, 2]), \"Winter\")\n",
    "         .when(F.month(F.col(\"order_date\")).isin([3, 4, 5]), \"Spring\")\n",
    "         .when(F.month(F.col(\"order_date\")).isin([6, 7, 8]), \"Summer\")\n",
    "         .otherwise(\"Fall\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"Enriched orders dataset created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating enriched orders: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2f52834-4433-46fb-b9e1-4f56920a7818",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer analytics dataset created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create customer analytics dataset\n",
    "try:\n",
    "    # Calculate customer metrics\n",
    "    df_customer_analytics = df_enriched_orders.groupBy(\"customer_id\") \\\n",
    "        .agg(\n",
    "            F.count(\"order_id\").alias(\"total_orders\"),\n",
    "            F.sum(\"order_amount\").alias(\"total_spent\"),\n",
    "            F.avg(\"order_amount\").alias(\"avg_order_value\"),\n",
    "            F.min(\"order_date\").alias(\"first_order_date\"),\n",
    "            F.max(\"order_date\").alias(\"last_order_date\"),\n",
    "            F.countDistinct(\"product_id\").alias(\"unique_products_purchased\"),\n",
    "            F.countDistinct(\"category\").alias(\"unique_categories_purchased\"),\n",
    "            F.sum(\"order_profit_margin\").alias(\"total_profit_generated\"),\n",
    "            F.avg(\"estimated_clv\").alias(\"avg_estimated_clv\")\n",
    "        )\n",
    "    \n",
    "    # Join with customer details\n",
    "    df_customer_analytics = df_customer_analytics.join(df_customers_renamed, \"customer_id\", \"left\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    df_customer_analytics = df_customer_analytics.withColumn(\n",
    "        \"days_since_first_order\",\n",
    "        F.datediff(F.current_date(), F.col(\"first_order_date\"))\n",
    "    ).withColumn(\n",
    "        \"days_since_last_order\",\n",
    "        F.datediff(F.current_date(), F.col(\"last_order_date\"))\n",
    "    ).withColumn(\n",
    "        \"order_frequency_days\",\n",
    "        F.col(\"days_since_first_order\") / F.col(\"total_orders\")\n",
    "    )\n",
    "    \n",
    "    # Create customer segments\n",
    "    df_customer_analytics = df_customer_analytics.withColumn(\n",
    "        \"customer_segment\",\n",
    "        F.when((F.col(\"total_spent\") >= 1000) & (F.col(\"total_orders\") >= 5), \"VIP\")\n",
    "         .when((F.col(\"total_spent\") >= 500) & (F.col(\"total_orders\") >= 3), \"High Value\")\n",
    "         .when((F.col(\"total_spent\") >= 200) & (F.col(\"total_orders\") >= 2), \"Medium Value\")\n",
    "         .otherwise(\"Low Value\")\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"Customer analytics dataset created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating customer analytics: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "659f2ce2-b69f-4a12-87e7-a83f0d4cfe09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product analytics dataset created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create product analytics dataset\n",
    "try:\n",
    "    # Calculate product metrics\n",
    "    df_product_analytics = df_enriched_orders.groupBy(\"product_id\") \\\n",
    "        .agg(\n",
    "            F.count(\"order_id\").alias(\"total_orders\"),\n",
    "            F.sum(\"order_amount\").alias(\"total_revenue\"),\n",
    "            F.avg(\"order_amount\").alias(\"avg_order_value\"),\n",
    "            F.countDistinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "            F.sum(\"order_profit_margin\").alias(\"total_profit\"),\n",
    "            F.min(\"order_date\").alias(\"first_order_date\"),\n",
    "            F.max(\"order_date\").alias(\"last_order_date\")\n",
    "        )\n",
    "    \n",
    "    # Join with product details\n",
    "    df_product_analytics = df_product_analytics.join(df_products_renamed, \"product_id\", \"left\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    df_product_analytics = df_product_analytics.withColumn(\n",
    "        \"days_since_first_order\",\n",
    "        F.datediff(F.current_date(), F.col(\"first_order_date\"))\n",
    "    ).withColumn(\n",
    "        \"days_since_last_order\",\n",
    "        F.datediff(F.current_date(), F.col(\"last_order_date\"))\n",
    "    ).withColumn(\n",
    "        \"order_frequency_days\",\n",
    "        F.col(\"days_since_first_order\") / F.col(\"total_orders\")\n",
    "    ).withColumn(\n",
    "        \"revenue_per_customer\",\n",
    "        F.col(\"total_revenue\") / F.col(\"unique_customers\")\n",
    "    )\n",
    "    \n",
    "    # Create product performance categories\n",
    "    df_product_analytics = df_product_analytics.withColumn(\n",
    "        \"performance_category\",\n",
    "        F.when((F.col(\"total_revenue\") >= 5000) & (F.col(\"total_orders\") >= 20), \"Star\")\n",
    "         .when((F.col(\"total_revenue\") >= 2000) & (F.col(\"total_orders\") >= 10), \"High Performer\")\n",
    "         .when((F.col(\"total_revenue\") >= 500) & (F.col(\"total_orders\") >= 5), \"Medium Performer\")\n",
    "         .otherwise(\"Low Performer\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"Product analytics dataset created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating product analytics: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fccd066b-0437-4532-9fbe-f5c769ac6c14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote enriched orders to `event-driven-catalog`.default.enriched_orders\nSuccessfully wrote customer analytics to `event-driven-catalog`.default.customer_analytics\nError writing enriched datasets: name 'product_analytics_table' is not defined\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8163591754436618>, line 12\u001B[0m\n",
       "\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully wrote customer analytics to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcustomer_analytics_table\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m# Write product analytics\u001B[39;00m\n",
       "\u001B[0;32m---> 12\u001B[0m     df_product_analytics\u001B[38;5;241m.\u001B[39mwrite\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelta\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverwrite\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msaveAsTable(product_analytics_table)\n",
       "\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully wrote product analytics to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mproduct_analytics_table\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'product_analytics_table' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'product_analytics_table' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'product_analytics_table' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KD00G",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8163591754436618>, line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully wrote customer analytics to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcustomer_analytics_table\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m# Write product analytics\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m     df_product_analytics\u001B[38;5;241m.\u001B[39mwrite\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelta\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverwrite\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msaveAsTable(product_analytics_table)\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully wrote product analytics to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mproduct_analytics_table\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
        "\u001B[0;31mNameError\u001B[0m: name 'product_analytics_table' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write enriched datasets to tables\n",
    "try:\n",
    "    # Write enriched orders\n",
    "    df_enriched_orders.write.format(\"delta\").mode(\"overwrite\").saveAsTable(enriched_orders_table)\n",
    "    print(f\"Successfully wrote enriched orders to {enriched_orders_table}\")\n",
    "    \n",
    "    # Write customer analytics\n",
    "    df_customer_analytics.write.format(\"delta\").mode(\"overwrite\").saveAsTable(customer_analytics_table)\n",
    "    print(f\"Successfully wrote customer analytics to {customer_analytics_table}\")\n",
    "    \n",
    "    # Write product analytics\n",
    "    df_product_analytics.write.format(\"delta\").mode(\"overwrite\").saveAsTable(products_analytics_table)\n",
    "    print(f\"Successfully wrote product analytics to {products_analytics_table}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing enriched datasets: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70c9b507-29d4-47e7-a6cf-71751a5357cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07_data_enrichment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}