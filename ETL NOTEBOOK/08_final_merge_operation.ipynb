{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d9ab5d8-c24d-4216-8f78-fa7b30f01562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Final Merge Operation and Data Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aacfe93-a516-4e73-82ac-91e5fa54a615",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**This notebook performs the final merge operation to consolidate all processed data into target table with SCD2 ( Slowly Changing Dimension) logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "576e15ad-70a9-4bdd-ba64-c76ab3fa9a3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "#Source table\n",
    "enriched_orders_table = \"`event-driven-catalog`.default.enriched_orders\"\n",
    "customer_analytics_table = \"`event-driven-catalog`.default.customer_analytics\"\n",
    "products_analytics_table = \"`event-driven-catalog`.default.products_analytics\"\n",
    "\n",
    "#Target table\n",
    "\n",
    "orders_target = \"`event-driven-catalog`.default.orders_target\"\n",
    "customers_target = \"`event-driven-catalog`.default.customers_target\"\n",
    "products_target = \"`event-driven-catalog`.default.products_target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b42c6c55-f178-4bd5-85a0-e6b0d6346544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded enriched datasets\nEnriched orders: 20 records\nCustomer analytics: 20 records\nProduct analytics: 20 records\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Read enriched data\n",
    "try:\n",
    "    df_enriched_orders = spark.read.table(enriched_orders_table)\n",
    "    df_customer_analytics = spark.read.table(customer_analytics_table)\n",
    "    df_product_analytics = spark.read.table(products_analytics_table)\n",
    "    \n",
    "    print(\"Successfully loaded enriched datasets\")\n",
    "    print(f\"Enriched orders: {df_enriched_orders.count()} records\")\n",
    "    print(f\"Customer analytics: {df_customer_analytics.count()} records\")\n",
    "    print(f\"Product analytics: {df_product_analytics.count()} records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading enriched datasets: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c95c9b84-c79d-42bf-bd94-85276b56fe01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders merge completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Merge Orders Data with SCD2 Logic\n",
    "try:\n",
    "    # Prepare orders data for merge\n",
    "    df_orders_merge = df_enriched_orders.select(\n",
    "        \"order_id\", \"customer_id\", \"product_id\", \"order_date\", \"order_amount\",\n",
    "        \"currency\", \"payment_method\", \"shipping_address\", \"order_status\",\n",
    "        \"created_timestamp\", \"processed_timestamp\", \"batch_id\", \"source_system\",\n",
    "        \"order_profit_margin\", \"estimated_clv\", \"season\"\n",
    "    ).withColumn(\"effective_date\", F.current_date()) \\\n",
    "     .withColumn(\"expiry_date\", F.lit(None).cast(DateType())) \\\n",
    "     .withColumn(\"is_current\", F.lit(True))\n",
    "    \n",
    "    # Check if target table exists\n",
    "    if spark.catalog.tableExists(orders_target):\n",
    "        # Perform SCD2 merge\n",
    "        target_orders = DeltaTable.forName(spark, orders_target)\n",
    "        \n",
    "        # Set expiry date for existing records that will be updated\n",
    "        target_orders.update(\n",
    "            condition=F.col(\"order_id\").isin([row.order_id for row in df_orders_merge.select(\"order_id\").distinct().collect()]),\n",
    "            set={\n",
    "                \"expiry_date\": F.current_date(),\n",
    "                \"is_current\": F.lit(False)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Insert new records\n",
    "        df_orders_merge.write.format(\"delta\").mode(\"append\").saveAsTable(orders_target)\n",
    "        \n",
    "    else:\n",
    "        # Create new table\n",
    "        df_orders_merge.write.format(\"delta\").saveAsTable(orders_target)\n",
    "    \n",
    "    print(\"Orders merge completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error merging orders data: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ee7be8-ebd5-4a88-addf-e58ceb46f291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers merge completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Merge Customers Data with SCD2 Logic\n",
    "\n",
    "try:\n",
    "    df_customers_merge = df_customer_analytics.select(\n",
    "        \"customer_id\", \"first_name\", \"last_name\", \"email\", \"phone\",\n",
    "        \"date_of_birth\", \"registration_date\", \"address\", \"city\", \"state\",\n",
    "        \"zip_code\", \"country\", \"customer_tier\", \"last_login\", \"customer_created_timestamp\",\n",
    "        \"age\", \"age_segment\", \"customer_lifecycle_stage\",\n",
    "        \"total_orders\", \"total_spent\", \"avg_order_value\", \"customer_segment\"\n",
    "    ).withColumn(\"effective_date\", F.current_date()) \\\n",
    "     .withColumn(\"expiry_date\", F.lit(None).cast(DateType())) \\\n",
    "     .withColumn(\"is_current\", F.lit(True))\n",
    "    \n",
    "    if spark.catalog.tableExists(customers_target):\n",
    "        target_customers = DeltaTable.forName(spark, customers_target)\n",
    "        target_customers.update(\n",
    "            condition=F.col(\"customer_id\").isin([row.customer_id for row in df_customers_merge.select(\"customer_id\").distinct().collect()]),\n",
    "            set={\n",
    "                \"expiry_date\": F.current_date(),\n",
    "                \"is_current\": F.lit(False)\n",
    "            }\n",
    "        )\n",
    "        df_customers_merge.write.format(\"delta\").mode(\"append\").saveAsTable(customers_target)\n",
    "    else:\n",
    "        df_customers_merge.write.format(\"delta\").saveAsTable(customers_target)\n",
    "    print(\"Customers merge completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error merging customers data: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a401ed-95e6-47b3-8413-fcbf567a9859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products merge completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Merge Products Data with SCD2 Logic\n",
    "try:\n",
    "    # Prepare products data for merge\n",
    "    df_products_merge = df_product_analytics.select(\n",
    "        \"product_id\", \"product_name\", \"category\", \"subcategory\", \"brand\",\n",
    "        \"price\", \"product_currency\", \"product_stock_quantity\", \"product_weight_kg\", \"dimensions_cm\",\n",
    "        \"color\", \"material\", \"description\", \"launch_date\", \"discontinued\",\n",
    "        \"product_created_timestamp\", \"product_price_segment\", \"product_stock_status\",\n",
    "        \"total_orders\",\"total_revenue\", \"unique_customers\", \"performance_category\",\n",
    "    ).withColumn(\"effective_date\", F.current_date()) \\\n",
    "     .withColumn(\"expiry_date\", F.lit(None).cast(DateType())) \\\n",
    "     .withColumn(\"is_current\", F.lit(True))\n",
    "    \n",
    "    # Check if target table exists\n",
    "    if spark.catalog.tableExists(products_target):\n",
    "        # Perform SCD2 merge\n",
    "        target_products = DeltaTable.forName(spark, products_target)\n",
    "        \n",
    "        # Set expiry date for existing records that will be updated\n",
    "        target_products.update(\n",
    "            condition=F.col(\"product_id\").isin([row.product_id for row in df_products_merge.select(\"product_id\").distinct().collect()]),\n",
    "            set={\n",
    "                \"expiry_date\": F.current_date(),\n",
    "                \"is_current\": F.lit(False)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Insert new records\n",
    "        df_products_merge.write.format(\"delta\").mode(\"append\").saveAsTable(products_target)\n",
    "        \n",
    "    else:\n",
    "        # Create new table\n",
    "        df_products_merge.write.format(\"delta\").saveAsTable(products_target)\n",
    "    \n",
    "    print(\"Products merge completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error merging products data: {str(e)}\")\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "08_final_merge_operation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}